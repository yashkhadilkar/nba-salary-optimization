{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6cc89503-f0f2-4144-9190-640d659795a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee946fb9-6b5a-4050-9905-2d9101ffc320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: 2025-07-27 13:41:16\n"
     ]
    }
   ],
   "source": [
    "print(f\"Started: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e8a62c-422e-48e1-ac12-dbadfb3b33e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading raw datasets\n",
      "Player stats: 4,323 records\n",
      "Advanced stats: 4,323 records\n",
      "Salary data: 256 records\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data():\n",
    "    \"\"\"Load all the datasets you collected yesterday\"\"\"\n",
    "    print(\"\\nLoading raw datasets\")\n",
    "    \n",
    "    try:\n",
    "        # Load player stats\n",
    "        player_stats = pd.read_csv('data/raw/player_stats_2020_2025.csv')\n",
    "        print(f\"Player stats: {len(player_stats):,} records\")\n",
    "        \n",
    "        # Load advanced stats  \n",
    "        advanced_stats = pd.read_csv('data/raw/advanced_stats_2020_2025.csv')\n",
    "        print(f\"Advanced stats: {len(advanced_stats):,} records\")\n",
    "        \n",
    "        # Load salary data\n",
    "        salary_data = pd.read_csv('data/raw/salary_data_2025.csv')\n",
    "        print(f\"Salary data: {len(salary_data):,} records\")\n",
    "        \n",
    "        return player_stats, advanced_stats, salary_data\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        print(\"Make sure you're running this from the project root directory\")\n",
    "        return None, None, None\n",
    "\n",
    "# Load the data\n",
    "player_stats, advanced_stats, salary_data = load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3edf0009-fb03-4b47-a1c8-e8dab697ff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Player Stats Data Quality Assessment:\n",
      "----------------------------------------\n",
      "Shape: (4323, 33)\n",
      "Memory usage: 1.1 MB\n",
      "\n",
      "Missing Values:\n",
      "   Rk: 6 (0.1%)\n",
      "   Age: 6 (0.1%)\n",
      "   Team: 6 (0.1%)\n",
      "   Pos: 6 (0.1%)\n",
      "   G: 6 (0.1%)\n",
      "   GS: 6 (0.1%)\n",
      "   MP: 6 (0.1%)\n",
      "   FG: 6 (0.1%)\n",
      "   FGA: 6 (0.1%)\n",
      "   FG%: 34 (0.8%)\n",
      "   3P: 6 (0.1%)\n",
      "   3PA: 6 (0.1%)\n",
      "   3P%: 257 (5.9%)\n",
      "   2P: 6 (0.1%)\n",
      "   2PA: 6 (0.1%)\n",
      "   2P%: 71 (1.6%)\n",
      "   eFG%: 34 (0.8%)\n",
      "   FT: 6 (0.1%)\n",
      "   FTA: 6 (0.1%)\n",
      "   FT%: 297 (6.9%)\n",
      "   ORB: 6 (0.1%)\n",
      "   DRB: 6 (0.1%)\n",
      "   TRB: 6 (0.1%)\n",
      "   AST: 6 (0.1%)\n",
      "   STL: 6 (0.1%)\n",
      "   BLK: 6 (0.1%)\n",
      "   TOV: 6 (0.1%)\n",
      "   PF: 6 (0.1%)\n",
      "   PTS: 6 (0.1%)\n",
      "   Trp-Dbl: 6 (0.1%)\n",
      "   Awards: 4,003 (92.6%)\n",
      "\n",
      "Data Types:\n",
      "float64    28\n",
      "object      4\n",
      "int64       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicates: 0\n",
      "\n",
      "Sample Data:\n",
      "    Rk          Player   Age Team Pos     G    GS      MP     FG     FGA  ...  \\\n",
      "0  1.0    James Harden  30.0  HOU  SG  68.0  68.0  2483.0  672.0  1514.0  ...   \n",
      "1  2.0  Damian Lillard  29.0  POR  PG  66.0  66.0  2474.0  624.0  1349.0  ...   \n",
      "\n",
      "     TRB    AST    STL   BLK    TOV     PF     PTS  Trp-Dbl         Awards  \\\n",
      "0  446.0  512.0  125.0  60.0  308.0  227.0  2335.0      4.0  MVP-3,AS,NBA1   \n",
      "1  284.0  530.0   70.0  22.0  194.0  114.0  1978.0      1.0  MVP-8,AS,NBA2   \n",
      "\n",
      "   Season  \n",
      "0    2020  \n",
      "1    2020  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "\n",
      "Advanced Stats Data Quality Assessment:\n",
      "----------------------------------------\n",
      "Shape: (4323, 30)\n",
      "Memory usage: 1.0 MB\n",
      "\n",
      "Missing Values:\n",
      "   Rk: 6 (0.1%)\n",
      "   Age: 6 (0.1%)\n",
      "   Team: 6 (0.1%)\n",
      "   Pos: 6 (0.1%)\n",
      "   G: 6 (0.1%)\n",
      "   GS: 6 (0.1%)\n",
      "   MP: 6 (0.1%)\n",
      "   PER: 6 (0.1%)\n",
      "   TS%: 32 (0.7%)\n",
      "   3PAr: 34 (0.8%)\n",
      "   FTr: 34 (0.8%)\n",
      "   TOV%: 27 (0.6%)\n",
      "   OWS: 6 (0.1%)\n",
      "   DWS: 6 (0.1%)\n",
      "   WS: 6 (0.1%)\n",
      "   WS/48: 6 (0.1%)\n",
      "   OBPM: 6 (0.1%)\n",
      "   DBPM: 6 (0.1%)\n",
      "   BPM: 6 (0.1%)\n",
      "   VORP: 6 (0.1%)\n",
      "   Awards: 4,003 (92.6%)\n",
      "\n",
      "Data Types:\n",
      "float64    25\n",
      "object      4\n",
      "int64       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicates: 0\n",
      "\n",
      "Sample Data:\n",
      "    Rk        Player   Age Team Pos     G    GS      MP   PER    TS%  ...  \\\n",
      "0  1.0   CJ McCollum  28.0  POR  SG  70.0  70.0  2556.0  17.0  0.541  ...   \n",
      "1  2.0  Devin Booker  23.0  PHO  SG  70.0  70.0  2512.0  20.6  0.618  ...   \n",
      "\n",
      "   OWS  DWS   WS  WS/48  OBPM  DBPM  BPM  VORP  Awards  Season  \n",
      "0  3.5  0.6  4.1  0.077   2.3  -1.8  0.5   1.6     NaN    2020  \n",
      "1  6.0  1.5  7.5  0.143   3.4  -1.3  2.2   2.6      AS    2020  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "\n",
      "Salary Data Data Quality Assessment:\n",
      "----------------------------------------\n",
      "Shape: (256, 10)\n",
      "Memory usage: 0.0 MB\n",
      "\n",
      "Missing Values:\n",
      "   2027-28: 104 (40.6%)\n",
      "   2028-29: 189 (73.8%)\n",
      "   2029-30: 248 (96.9%)\n",
      "   2030-31: 256 (100.0%)\n",
      "   Guaranteed: 16 (6.2%)\n",
      "\n",
      "Data Types:\n",
      "object     6\n",
      "int64      3\n",
      "float64    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duplicates: 0\n",
      "\n",
      "Sample Data:\n",
      "   Rk         Player   Tm   2025-26   2026-27      2027-28      2028-29  \\\n",
      "0   1  Stephen Curry  GSW  59606817  62587158          NaN          NaN   \n",
      "1   2    Joel Embiid  PHI  55224526  57985752  $62,624,612  $67,263,472   \n",
      "\n",
      "  2029-30  2030-31    Guaranteed  \n",
      "0     NaN      NaN  $122,193,975  \n",
      "1     NaN      NaN  $175,834,890  \n",
      "\n",
      " ASSESSMENT SUMMARY:\n",
      "   Total records across all datasets: 8,902\n",
      "   Ready for Phase 2: Data Cleaning!\n"
     ]
    }
   ],
   "source": [
    "def assess_data_quality(df, name):\n",
    "    \"\"\"Comprehensive data quality assessment\"\"\"\n",
    "    print(f\"\\n{name} Data Quality Assessment:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage().sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.any():\n",
    "        print(f\"\\nMissing Values:\")\n",
    "        missing_pct = (missing / len(df)) * 100\n",
    "        for col in missing[missing > 0].index:\n",
    "            print(f\"   {col}: {missing[col]:,} ({missing_pct[col]:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No missing values!\")\n",
    "    \n",
    "    # Data types\n",
    "    print(f\"\\nData Types:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    \n",
    "    # Duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\nDuplicates: {duplicates:,}\")\n",
    "    \n",
    "    # Sample data\n",
    "    print(f\"\\nSample Data:\")\n",
    "    print(df.head(2))\n",
    "    \n",
    "    return {\n",
    "        'shape': df.shape,\n",
    "        'missing_values': missing.sum(),\n",
    "        'duplicates': duplicates,\n",
    "        'columns': list(df.columns)\n",
    "    }\n",
    "\n",
    "# Assess each dataset\n",
    "if player_stats is not None:\n",
    "    player_quality = assess_data_quality(player_stats, \"Player Stats\")\n",
    "    advanced_quality = assess_data_quality(advanced_stats, \"Advanced Stats\") \n",
    "    salary_quality = assess_data_quality(salary_data, \"Salary Data\")\n",
    "    \n",
    "    print(f\"\\n ASSESSMENT SUMMARY:\")\n",
    "    print(f\"   Total records across all datasets: {len(player_stats) + len(advanced_stats) + len(salary_data):,}\")\n",
    "    print(f\"   Ready for Phase 2: Data Cleaning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cf93272-1fd2-4c82-8757-a0f72c8cb8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Player Stats Data...\n",
      "   Original records: 4,323\n",
      "   After deduplication: 3,360\n",
      "   Cleaning player names...\n",
      "   Standardizing team names...\n",
      "   Handling missing values...\n",
      "   Adding derived metrics...\n",
      "   Players with significant playing time: 2,627\n",
      "Player stats cleaning complete!\n",
      "Final dataset: 3,360 player-seasons\n",
      "Cleaned Player Stats Summary:\n",
      "Seasons: [2020, 2021, 2022, 2023, 2024, 2025]\n",
      "   Teams: ['2TM', '3TM', '4TM', 'ATL', 'BKN', 'BOS', 'CHA', 'CHI', 'CLE', 'DAL', 'DEN', 'DET', 'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NOR', 'NYK', 'OKC', 'ORL', 'PHI', 'PHX', 'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS']\n",
      "   Positions: ['C', 'PF', 'PG', 'SF', 'SG']\n",
      "   Top scorers by season:\n",
      "     2020: James Harden (2335 pts)\n",
      "     2021: Stephen Curry (2015 pts)\n",
      "     2022: Trae Young (2155 pts)\n",
      "     2023: Jayson Tatum (2225 pts)\n",
      "     2024: Luka Dončić (2370 pts)\n",
      "     2025: Shai Gilgeous-Alexander (2484 pts)\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Clean Player Stats Data\n",
    "\n",
    "def clean_player_stats(df):\n",
    "    \"\"\"Clean and standardize player stats data\"\"\"\n",
    "    print(\"Cleaning Player Stats Data...\")\n",
    "\n",
    "    cleaned = df.copy()\n",
    "\n",
    "    print(f\"   Original records: {len(cleaned):,}\")\n",
    "\n",
    "    def handle_duplicate_players(group):\n",
    "        if len(group) == 1:\n",
    "            return group\n",
    "\n",
    "        tot_records = group[group['Team'] == 'TOT']\n",
    "        if len(tot_records) > 0:\n",
    "            return tot_records\n",
    "        \n",
    "        # Otherwise, keep the record with most games played\n",
    "        return group.loc[[group['G'].idxmax()]]\n",
    "\n",
    "    cleaned = cleaned.groupby(['Player', 'Season']).apply(handle_duplicate_players).reset_index(drop=True)\n",
    "    print(f\"   After deduplication: {len(cleaned):,}\")\n",
    "\n",
    "    print(\"   Cleaning player names...\")\n",
    "    cleaned['Player_Clean'] = cleaned['Player'].str.strip()\n",
    "\n",
    "    cleaned['Player_Clean'] = cleaned['Player_Clean'].str.replace('*', '', regex=False)\n",
    "    cleaned['Player_Clean'] = cleaned['Player_Clean'].str.replace('\\\\\\\\', '', regex=False)\n",
    "\n",
    "    print(\"   Standardizing team names...\")\n",
    "    team_mapping = {\n",
    "        'CHO': 'CHA',  # Charlotte\n",
    "        'NOP': 'NOR',  # New Orleans (sometimes listed differently)\n",
    "        'PHO': 'PHX',  # Phoenix (sometimes listed differently)\n",
    "        'BRK': 'BKN',  # Brooklyn\n",
    "        'TOT': 'TOT'   # Total (for traded players)\n",
    "    }\n",
    "    \n",
    "    cleaned['Team_Clean'] = cleaned['Team'].replace(team_mapping)\n",
    "\n",
    "    print(\"   Handling missing values...\")\n",
    "\n",
    "    percentage_cols = ['FG%', '3P%', '2P%', 'eFG%', 'FT%']\n",
    "    for col in percentage_cols:\n",
    "        if col in cleaned.columns:\n",
    "            # If attempts are 0, set percentage to 0\n",
    "            attempt_col = col.replace('%', 'A')  # FG% -> FGA\n",
    "            if attempt_col in cleaned.columns:\n",
    "                mask = (cleaned[attempt_col] == 0) | (cleaned[attempt_col].isna())\n",
    "                cleaned.loc[mask, col] = 0\n",
    "            \n",
    "            # For remaining missing percentages, use median by position\n",
    "            cleaned[col] = cleaned.groupby('Pos')[col].transform(\n",
    "                lambda x: x.fillna(x.median())\n",
    "            )\n",
    "\n",
    "    counting_cols = ['G', 'GS', 'MP', 'FG', 'FGA', '3P', '3PA', '2P', '2PA', \n",
    "                    'FT', 'FTA', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "    for col in counting_cols:\n",
    "        if col in cleaned.columns:\n",
    "            cleaned[col] = cleaned[col].fillna(0)\n",
    "\n",
    "    print(\"   Adding derived metrics...\")\n",
    "\n",
    "    cleaned['MPG'] = cleaned['MP'] / cleaned['G']\n",
    "    cleaned['MPG'] = cleaned['MPG'].fillna(0)\n",
    "\n",
    "    cleaned['PPG'] = cleaned['PTS'] / cleaned['G']\n",
    "    cleaned['PPG'] = cleaned['PPG'].fillna(0)\n",
    "\n",
    "    cleaned['RPG'] = cleaned['TRB'] / cleaned['G']\n",
    "    cleaned['RPG'] = cleaned['RPG'].fillna(0)\n",
    "\n",
    "    cleaned['APG'] = cleaned['AST'] / cleaned['G']\n",
    "    cleaned['APG'] = cleaned['APG'].fillna(0)\n",
    "    \n",
    "    # 6. Filter out players with minimal playing time\n",
    "    # Keep only players who played at least 5 games and 10 minutes per game on average\n",
    "    min_games = 5\n",
    "    min_mpg = 10\n",
    "    \n",
    "    significant_players = (cleaned['G'] >= min_games) & (cleaned['MPG'] >= min_mpg)\n",
    "    print(f\"   Players with significant playing time: {significant_players.sum():,}\")\n",
    "    \n",
    "    # Keep both datasets - all players and significant players\n",
    "    cleaned['Significant_Player'] = significant_players\n",
    "    \n",
    "    print(f\"Player stats cleaning complete!\")\n",
    "    print(f\"Final dataset: {len(cleaned):,} player-seasons\")\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "\n",
    "clean_player_stats_df = clean_player_stats(player_stats)\n",
    "\n",
    "print(f\"Cleaned Player Stats Summary:\")\n",
    "print(f\"Seasons: {sorted(clean_player_stats_df['Season'].unique())}\")\n",
    "\n",
    "# Handle NaN values in team names\n",
    "teams = clean_player_stats_df['Team_Clean'].dropna().unique()\n",
    "print(f\"   Teams: {sorted(teams)}\")\n",
    "\n",
    "positions = clean_player_stats_df['Pos'].dropna().unique() \n",
    "print(f\"   Positions: {sorted(positions)}\")\n",
    "\n",
    "print(f\"   Top scorers by season:\")\n",
    "for season in sorted(clean_player_stats_df['Season'].unique()):\n",
    "    season_data = clean_player_stats_df[clean_player_stats_df['Season'] == season]\n",
    "    if len(season_data) > 0:\n",
    "        valid_data = season_data.dropna(subset=['PTS'])\n",
    "        if len(valid_data) > 0:\n",
    "            top_scorer = valid_data.loc[valid_data['PTS'].idxmax()]\n",
    "            print(f\"     {season}: {top_scorer['Player_Clean']} ({top_scorer['PTS']:.0f} pts)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e753ea1a-0d48-41f4-806b-1585be4772d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_advanced_stats(df):\n",
    "    \"\"\"Clean and standardize advanced stats data\"\"\"\n",
    "    print(\"Cleaning Advanced Stats Data...\")\n",
    "    \n",
    "    cleaned = df.copy()\n",
    "\n",
    "    print(f\"   Original records: {len(cleaned):,}\")\n",
    "    \n",
    "    def handle_duplicate_players_advanced(group):\n",
    "        if len(group) == 1:\n",
    "            return group\n",
    "        \n",
    "        # If there's a \"TOT\" record, keep that\n",
    "        tot_records = group[group['Team'] == 'TOT']\n",
    "        if len(tot_records) > 0:\n",
    "            return tot_records\n",
    "        \n",
    "        # Otherwise, keep the record with most minutes played\n",
    "        if 'MP' in group.columns:\n",
    "            return group.loc[[group['MP'].astype(str).str.replace(',', '').astype(float).idxmax()]]\n",
    "        else:\n",
    "            return group.iloc[[0]]  # Keep first record if no MP column\n",
    "    \n",
    "    # Convert MP to numeric if it's string\n",
    "    if 'MP' in cleaned.columns and cleaned['MP'].dtype == 'object':\n",
    "        cleaned['MP'] = pd.to_numeric(cleaned['MP'].astype(str).str.replace(',', ''), errors='coerce')\n",
    "    \n",
    "    cleaned = cleaned.groupby(['Player', 'Season']).apply(handle_duplicate_players_advanced).reset_index(drop=True)\n",
    "    print(f\"   After deduplication: {len(cleaned):,}\")\n",
    "\n",
    "    print(\"   Cleaning player names...\")\n",
    "    cleaned['Player_Clean'] = cleaned['Player'].str.strip()\n",
    "    cleaned['Player_Clean'] = cleaned['Player_Clean'].str.replace('*', '', regex=False)\n",
    "    cleaned['Player_Clean'] = cleaned['Player_Clean'].str.replace('\\\\\\\\', '', regex=False)\n",
    "\n",
    "    team_mapping = {\n",
    "        'CHO': 'CHA', 'NOP': 'NOR', 'PHO': 'PHX', 'BRK': 'BKN', 'TOT': 'TOT'\n",
    "    }\n",
    "    cleaned['Team_Clean'] = cleaned['Team'].replace(team_mapping)\n",
    "\n",
    "    print(\"   Handling missing values for advanced stats...\")\n",
    "    \n",
    "    # Advanced stats that should be filled with position medians\n",
    "    advanced_cols = ['PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', \n",
    "                    'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', \n",
    "                    'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "    \n",
    "    for col in advanced_cols:\n",
    "        if col in cleaned.columns:\n",
    "            # Fill missing values with position median\n",
    "            cleaned[col] = cleaned.groupby('Pos')[col].transform(\n",
    "                lambda x: x.fillna(x.median())\n",
    "            )\n",
    "            \n",
    "            # If still missing (entire position missing), fill with overall median\n",
    "            cleaned[col] = cleaned[col].fillna(cleaned[col].median())\n",
    "\n",
    "    print(\"   Converting data types...\")\n",
    "    \n",
    "    # Columns that should be numeric\n",
    "    numeric_cols = ['Age', 'G', 'GS', 'MP'] + advanced_cols\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in cleaned.columns:\n",
    "            if cleaned[col].dtype == 'object':\n",
    "                # Remove any non-numeric characters and convert\n",
    "                cleaned[col] = pd.to_numeric(\n",
    "                    cleaned[col].astype(str).str.replace('[^0-9.-]', '', regex=True), \n",
    "                    errors='coerce'\n",
    "                )\n",
    "\n",
    "    print(\"Adding quality indicators...\")\n",
    "    \n",
    "    # Flag players with sufficient playing time for reliable advanced stats\n",
    "    min_games_advanced = 10\n",
    "    min_minutes_total = 200\n",
    "    \n",
    "    if 'G' in cleaned.columns and 'MP' in cleaned.columns:\n",
    "        sufficient_sample = (cleaned['G'] >= min_games_advanced) & (cleaned['MP'] >= min_minutes_total)\n",
    "        cleaned['Reliable_Advanced_Stats'] = sufficient_sample\n",
    "        print(f\"   Players with reliable advanced stats: {sufficient_sample.sum():,}\")\n",
    "\n",
    "    print(\"   Handling outliers...\")\n",
    "    \n",
    "    # Cap extreme values that are likely data errors\n",
    "    outlier_caps = {\n",
    "        'PER': (0, 50),      # PER should be between 0-50\n",
    "        'BPM': (-15, 15),    # BPM rarely exceeds +/-15\n",
    "        'VORP': (-5, 15),    # VORP rarely exceeds these bounds\n",
    "        'USG%': (0, 50),     # Usage rate should be 0-50%\n",
    "        'WS': (-5, 25)       # Win shares rarely exceed these bounds\n",
    "    }\n",
    "    \n",
    "    for col, (min_val, max_val) in outlier_caps.items():\n",
    "        if col in cleaned.columns:\n",
    "            outliers_low = cleaned[col] < min_val\n",
    "            outliers_high = cleaned[col] > max_val\n",
    "            \n",
    "            if outliers_low.any():\n",
    "                print(f\"     Capping {outliers_low.sum()} low outliers in {col}\")\n",
    "                cleaned.loc[outliers_low, col] = min_val\n",
    "                \n",
    "            if outliers_high.any():\n",
    "                print(f\"     Capping {outliers_high.sum()} high outliers in {col}\")\n",
    "                cleaned.loc[outliers_high, col] = max_val\n",
    "    \n",
    "    print(f\" Advanced stats cleaning complete!\")\n",
    "    print(f\"   Final dataset: {len(cleaned):,} player-seasons\")\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76a16df7-7e10-46a8-a7c0-52f48f1fa08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Advanced Stats Data...\n",
      "   Original records: 4,323\n",
      "   After deduplication: 3,360\n",
      "   Cleaning player names...\n",
      "   Handling missing values for advanced stats...\n",
      "   Converting data types...\n",
      "Adding quality indicators...\n",
      "   Players with reliable advanced stats: 2,619\n",
      "   Handling outliers...\n",
      "     Capping 84 low outliers in PER\n",
      "     Capping 5 high outliers in PER\n",
      "     Capping 56 low outliers in BPM\n",
      "     Capping 12 high outliers in BPM\n",
      "     Capping 3 high outliers in USG%\n",
      " Advanced stats cleaning complete!\n",
      "   Final dataset: 3,360 player-seasons\n",
      "\n",
      "Cleaned Advanced Stats Summary:\n",
      "Key metrics available: ['PER', 'VORP', 'BPM', 'WS']\n",
      "   Top PER performers by season:\n",
      "     2020: Giannis Antetokounmpo (PER: 31.9)\n",
      "     2021: Nikola Jokić (PER: 31.3)\n",
      "     2022: Nikola Jokić (PER: 32.8)\n",
      "     2023: Nikola Jokić (PER: 31.5)\n",
      "     2024: Joel Embiid (PER: 34.1)\n",
      "     2025: Nikola Jokić (PER: 32.0)\n"
     ]
    }
   ],
   "source": [
    "if advanced_stats is not None:\n",
    "    clean_advanced_stats_df = clean_advanced_stats(advanced_stats)\n",
    "\n",
    "    print(f\"\\nCleaned Advanced Stats Summary:\")\n",
    "    print(f\"Key metrics available: {[col for col in ['PER', 'VORP', 'BPM', 'WS'] if col in clean_advanced_stats_df.columns]}\")\n",
    "\n",
    "    if 'PER' in clean_advanced_stats_df.columns:\n",
    "        print(f\"   Top PER performers by season:\")\n",
    "        for season in sorted(clean_advanced_stats_df['Season'].unique()):\n",
    "            season_data = clean_advanced_stats_df[\n",
    "                (clean_advanced_stats_df['Season'] == season) & \n",
    "                (clean_advanced_stats_df.get('Reliable_Advanced_Stats', True))\n",
    "            ]\n",
    "            if len(season_data) > 0:\n",
    "                top_per = season_data.loc[season_data['PER'].idxmax()]\n",
    "                print(f\"     {season}: {top_per['Player_Clean']} (PER: {top_per['PER']:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1623be1b-f60e-4422-8d2a-2e54f1467b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_salary_data(df):\n",
    "    \"\"\"Clean and standardize salary data\"\"\"\n",
    "    print(\"Cleaning Salary Data...\")\n",
    "    \n",
    "    cleaned = df.copy()\n",
    "\n",
    "    print(\"   Cleaning player names...\")\n",
    "    cleaned['Player_Clean'] = cleaned['Player'].str.strip()\n",
    "    cleaned['Player_Clean'] = cleaned['Player_Clean'].str.replace('*', '', regex=False)\n",
    "    cleaned['Player_Clean'] = cleaned['Player_Clean'].str.replace('\\\\\\\\', '', regex=False)\n",
    "\n",
    "    team_mapping = {\n",
    "        'CHO': 'CHA', 'NOP': 'NOR', 'PHO': 'PHX', 'BRK': 'BKN'\n",
    "    }\n",
    "    cleaned['Team_Clean'] = cleaned['Tm'].replace(team_mapping)\n",
    "\n",
    "    print(\"   Processing salary data...\")\n",
    "    \n",
    "    # Identify salary columns (should be the year columns like '2025-26')\n",
    "    salary_columns = [col for col in cleaned.columns if col.count('-') == 1 and len(col) == 7]\n",
    "    print(f\"   Found salary columns: {salary_columns}\")\n",
    "    \n",
    "    for col in salary_columns:\n",
    "        if col in cleaned.columns:\n",
    "            # Convert to numeric (should already be clean from your scraping)\n",
    "            cleaned[col] = pd.to_numeric(cleaned[col], errors='coerce')\n",
    "\n",
    "    print(\"   Creating salary metrics...\")\n",
    "    \n",
    "    # Current season salary (assuming 2025-26 is current)\n",
    "    current_salary_col = '2025-26'\n",
    "    if current_salary_col in cleaned.columns:\n",
    "        cleaned['Current_Salary'] = cleaned[current_salary_col]\n",
    "        \n",
    "        # Create salary categories\n",
    "        cleaned['Salary_Tier'] = pd.cut(\n",
    "            cleaned['Current_Salary'], \n",
    "            bins=[0, 5000000, 15000000, 30000000, float('inf')],\n",
    "            labels=['Rookie/Min', 'Role Player', 'Star', 'Superstar'],\n",
    "            include_lowest=True\n",
    "        )\n",
    "        \n",
    "        # Annual salary in millions for easier reading\n",
    "        cleaned['Salary_Millions'] = cleaned['Current_Salary'] / 1000000\n",
    "        \n",
    "    print(\"   Handling missing salary data...\")\n",
    "    \n",
    "    # Players without salary data might be:\n",
    "    # - Free agents\n",
    "    # - Retired players  \n",
    "    # - International players\n",
    "    # - Players with non-guaranteed contracts\n",
    "    \n",
    "    missing_salaries = cleaned['Current_Salary'].isna().sum()\n",
    "    print(f\"   Players with missing salary data: {missing_salaries}\")\n",
    "    \n",
    "    # For analysis purposes, we'll flag these players\n",
    "    cleaned['Has_Salary_Data'] = cleaned['Current_Salary'].notna()\n",
    "\n",
    "    print(\"   Adding contract analysis features...\")\n",
    "    \n",
    "    # Multi-year contract information (if we have future year data)\n",
    "    future_columns = [col for col in salary_columns if '2026' in col or '2027' in col or '2028' in col]\n",
    "    \n",
    "    if future_columns:\n",
    "        # Check if player has multi-year contract\n",
    "        cleaned['Multi_Year_Contract'] = cleaned[future_columns].notna().any(axis=1)\n",
    "        \n",
    "        # Calculate total contract value (for next 3 years)\n",
    "        next_3_years = [col for col in salary_columns if any(year in col for year in ['2025-26', '2026-27', '2027-28'])]\n",
    "        if len(next_3_years) >= 2:\n",
    "            cleaned['Total_Contract_Value'] = cleaned[next_3_years].sum(axis=1, skipna=True)\n",
    "    \n",
    "    print(f\"Salary data cleaning complete!\")\n",
    "    print(f\"Final dataset: {len(cleaned):,} players with contract data\")\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d008342-ebcf-4871-a691-374acdd8dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Salary Data...\n",
      "   Cleaning player names...\n",
      "   Processing salary data...\n",
      "   Found salary columns: ['2025-26', '2026-27', '2027-28', '2028-29', '2029-30', '2030-31']\n",
      "   Creating salary metrics...\n",
      "   Handling missing salary data...\n",
      "   Players with missing salary data: 0\n",
      "   Adding contract analysis features...\n",
      "Salary data cleaning complete!\n",
      "Final dataset: 256 players with contract data\n",
      "\n",
      " Cleaned Salary Data Summary:\n",
      "Players with salary data: 256\n",
      "   Salary distribution (millions):\n",
      "     Min: $0.3M\n",
      "     Median: $8.3M\n",
      "     Max: $59.6M\n",
      "   Salary tiers:\n",
      "     Rookie/Min: 99 players\n",
      "     Role Player: 76 players\n",
      "     Superstar: 48 players\n",
      "     Star: 33 players\n",
      "   Top 5 earners:\n",
      "     Stephen Curry: $59.6M\n",
      "     Joel Embiid: $55.2M\n",
      "     Nikola Jokić: $55.2M\n",
      "     Jayson Tatum: $54.1M\n",
      "     Giannis Antetokounmpo: $54.1M\n"
     ]
    }
   ],
   "source": [
    "if salary_data is not None:\n",
    "    clean_salary_data_df = clean_salary_data(salary_data)\n",
    "    \n",
    "    # Quick validation\n",
    "    print(f\"\\n Cleaned Salary Data Summary:\")\n",
    "    print(f\"Players with salary data: {clean_salary_data_df['Has_Salary_Data'].sum():,}\")\n",
    "    \n",
    "    if 'Current_Salary' in clean_salary_data_df.columns:\n",
    "        salary_stats = clean_salary_data_df['Current_Salary'].describe()\n",
    "        print(f\"   Salary distribution (millions):\")\n",
    "        print(f\"     Min: ${salary_stats['min']/1000000:.1f}M\")\n",
    "        print(f\"     Median: ${salary_stats['50%']/1000000:.1f}M\") \n",
    "        print(f\"     Max: ${salary_stats['max']/1000000:.1f}M\")\n",
    "        \n",
    "        print(f\"   Salary tiers:\")\n",
    "        tier_counts = clean_salary_data_df['Salary_Tier'].value_counts()\n",
    "        for tier, count in tier_counts.items():\n",
    "            print(f\"     {tier}: {count} players\")\n",
    "        \n",
    "        # Top earners\n",
    "        print(f\"   Top 5 earners:\")\n",
    "        top_earners = clean_salary_data_df.nlargest(5, 'Current_Salary')\n",
    "        for _, player in top_earners.iterrows():\n",
    "            print(f\"     {player['Player_Clean']}: ${player['Current_Salary']/1000000:.1f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "902dc4c6-0b08-43f6-9770-d1f0d3668045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Master Dataset...\n",
      "Checking for column conflicts...\n",
      "   Found overlapping columns: {'MP', 'Age', 'Rk', 'Team', 'G', 'GS', 'Team_Clean', 'Player', 'Pos', 'Awards'}\n",
      "   Player stats columns: 40\n",
      "   Advanced stats columns: 23\n",
      "   Merging basic and advanced stats...\n",
      "   After stats merge: 3,360 player-seasons\n",
      "   Adding current salary data...\n",
      "   Players with current salary data: 219\n",
      "   Calculating efficiency metrics...\n",
      "   Adding career stage classification...\n",
      " Master dataset creation complete!\n",
      "   Final dataset: 3,360 player-seasons\n",
      "   Unique players: 1,069\n",
      "   Seasons covered: [2020, 2021, 2022, 2023, 2024, 2025]\n"
     ]
    }
   ],
   "source": [
    "def create_master_dataset(player_stats_df, advanced_stats_df, salary_df):\n",
    "    \"\"\"Merge all datasets into a comprehensive master dataset - FIXED\"\"\"\n",
    "    print(\"Creating Master Dataset...\")\n",
    "\n",
    "    print(\"Checking for column conflicts...\")\n",
    "    \n",
    "    player_cols = set(player_stats_df.columns)\n",
    "    advanced_cols = set(advanced_stats_df.columns)\n",
    "\n",
    "    overlap_cols = player_cols.intersection(advanced_cols) - {'Player_Clean', 'Season'}\n",
    "    if overlap_cols:\n",
    "        print(f\"   Found overlapping columns: {overlap_cols}\")\n",
    "        advanced_stats_clean = advanced_stats_df.drop(columns=list(overlap_cols))\n",
    "    else:\n",
    "        advanced_stats_clean = advanced_stats_df\n",
    "    \n",
    "    print(f\"   Player stats columns: {len(player_stats_df.columns)}\")\n",
    "    print(f\"   Advanced stats columns: {len(advanced_stats_clean.columns)}\")\n",
    "\n",
    "    print(\"   Merging basic and advanced stats...\")\n",
    "    \n",
    "    stats_merged = pd.merge(\n",
    "        player_stats_df, \n",
    "        advanced_stats_clean,\n",
    "        on=['Player_Clean', 'Season'],\n",
    "        how='left',\n",
    "        suffixes=('', '_adv')\n",
    "    )\n",
    "    \n",
    "    print(f\"   After stats merge: {len(stats_merged):,} player-seasons\")\n",
    "\n",
    "    print(\"   Adding current salary data...\")\n",
    "\n",
    "    salary_lookup = salary_df[['Player_Clean', 'Current_Salary', 'Salary_Tier', 'Salary_Millions', 'Has_Salary_Data']].copy()\n",
    "\n",
    "    stats_merged['Current_Salary'] = np.nan\n",
    "    stats_merged['Salary_Tier'] = np.nan\n",
    "    stats_merged['Salary_Millions'] = np.nan\n",
    "    stats_merged['Has_Salary_Data'] = False\n",
    "    \n",
    "    # Fill in 2025 salary data\n",
    "    for _, salary_row in salary_lookup.iterrows():\n",
    "        if pd.notna(salary_row['Current_Salary']):\n",
    "            mask = (stats_merged['Player_Clean'] == salary_row['Player_Clean']) & (stats_merged['Season'] == 2025)\n",
    "            stats_merged.loc[mask, 'Current_Salary'] = salary_row['Current_Salary']\n",
    "            stats_merged.loc[mask, 'Salary_Tier'] = salary_row['Salary_Tier']\n",
    "            stats_merged.loc[mask, 'Salary_Millions'] = salary_row['Salary_Millions']\n",
    "            stats_merged.loc[mask, 'Has_Salary_Data'] = salary_row['Has_Salary_Data']\n",
    "    \n",
    "    current_salary_matches = stats_merged['Has_Salary_Data'].sum()\n",
    "    print(f\"   Players with current salary data: {current_salary_matches:,}\")\n",
    "\n",
    "    print(\"   Calculating efficiency metrics...\")\n",
    "    \n",
    "    # Only for players with salary data\n",
    "    has_salary = stats_merged['Current_Salary'].notna()\n",
    "    \n",
    "    if has_salary.any():\n",
    "        # Points per million dollars\n",
    "        stats_merged.loc[has_salary, 'Points_Per_Million'] = (\n",
    "            stats_merged.loc[has_salary, 'PTS'] / stats_merged.loc[has_salary, 'Salary_Millions']\n",
    "        )\n",
    "        \n",
    "        # Win Shares per million (if available)\n",
    "        if 'WS' in stats_merged.columns:\n",
    "            stats_merged.loc[has_salary, 'WinShares_Per_Million'] = (\n",
    "                stats_merged.loc[has_salary, 'WS'] / stats_merged.loc[has_salary, 'Salary_Millions']\n",
    "            )\n",
    "        \n",
    "        # VORP per million (if available)\n",
    "        if 'VORP' in stats_merged.columns:\n",
    "            stats_merged.loc[has_salary, 'VORP_Per_Million'] = (\n",
    "                stats_merged.loc[has_salary, 'VORP'] / stats_merged.loc[has_salary, 'Salary_Millions']\n",
    "            )\n",
    "\n",
    "    print(\"   Adding career stage classification...\")\n",
    "    \n",
    "    def classify_career_stage(age):\n",
    "        if pd.isna(age):\n",
    "            return 'Unknown'\n",
    "        if age <= 23:\n",
    "            return 'Rookie/Young'\n",
    "        elif age <= 27:\n",
    "            return 'Developing'\n",
    "        elif age <= 30:\n",
    "            return 'Prime'\n",
    "        elif age <= 34:\n",
    "            return 'Veteran'\n",
    "        else:\n",
    "            return 'Late Career'\n",
    "    \n",
    "    stats_merged['Career_Stage'] = stats_merged['Age'].apply(classify_career_stage)\n",
    "    \n",
    "    print(f\" Master dataset creation complete!\")\n",
    "    print(f\"   Final dataset: {len(stats_merged):,} player-seasons\")\n",
    "    print(f\"   Unique players: {stats_merged['Player_Clean'].nunique():,}\")\n",
    "    print(f\"   Seasons covered: {sorted(stats_merged['Season'].unique())}\")\n",
    "    \n",
    "    return stats_merged\n",
    "\n",
    "# Create the master dataset\n",
    "master_nba_data = create_master_dataset(\n",
    "    clean_player_stats_df, \n",
    "    clean_advanced_stats_df, \n",
    "    clean_salary_data_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4839ddf-4b27-469d-82a5-f1a8a534e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_datasets(master_data, player_stats, advanced_stats, salary_data):\n",
    "    \"\"\"Save all cleaned datasets for future use\"\"\"\n",
    "    print(\"Saving cleaned datasets...\")\n",
    "\n",
    "    os.makedirs('data/processed', exist_ok=True)\n",
    "    os.makedirs('data/processed/individual', exist_ok=True)\n",
    "\n",
    "    master_data.to_csv('data/processed/master_nba_data.csv', index=False)\n",
    "    print(f\"   Master dataset saved: {len(master_data):,} records\")\n",
    "    \n",
    "    # Save individual cleaned datasets\n",
    "    player_stats.to_csv('data/processed/individual/clean_player_stats.csv', index=False)\n",
    "    advanced_stats.to_csv('data/processed/individual/clean_advanced_stats.csv', index=False)\n",
    "    salary_data.to_csv('data/processed/individual/clean_salary_data.csv', index=False)\n",
    "    print(f\"   Individual datasets saved\")\n",
    "    \n",
    "    # Create data dictionary\n",
    "    data_dictionary = {\n",
    "        'master_dataset': {\n",
    "            'file': 'master_nba_data.csv',\n",
    "            'description': 'Complete NBA dataset with player stats, advanced metrics, and salary data',\n",
    "            'records': len(master_data),\n",
    "            'columns': len(master_data.columns),\n",
    "            'date_created': pd.Timestamp.now().isoformat(),\n",
    "            'key_columns': {\n",
    "                'Player_Clean': 'Standardized player name',\n",
    "                'Season': 'NBA season (2020-2025)',\n",
    "                'Team_Clean': 'Standardized team abbreviation',\n",
    "                'Current_Salary': 'Actual 2025 salary (where available)',\n",
    "                'Salary_Millions': 'Salary in millions for analysis',\n",
    "                'Points_Per_Million': 'Points scored per million dollars salary',\n",
    "                'WinShares_Per_Million': 'Win shares per million dollars salary',\n",
    "                'VORP_Per_Million': 'Value over replacement per million dollars salary',\n",
    "                'Career_Stage': 'Player career classification',\n",
    "                'Significant_Player': 'Flag for players with substantial playing time',\n",
    "                'Has_Salary_Data': 'Flag indicating if player has current salary data'\n",
    "            }\n",
    "        },\n",
    "        'data_quality': {\n",
    "            'player_seasons': len(master_data),\n",
    "            'unique_players': master_data['Player_Clean'].nunique(),\n",
    "            'seasons_covered': sorted(master_data['Season'].unique()),\n",
    "            'salary_coverage_pct': (master_data['Current_Salary'].notna().mean() * 100),\n",
    "            'teams_covered': sorted(master_data['Team_Clean'].dropna().unique()),\n",
    "            'efficiency_metrics_available': [col for col in master_data.columns if 'Per_Million' in col]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save data dictionary\n",
    "    with open('data/processed/data_dictionary.json', 'w') as f:\n",
    "        json.dump(data_dictionary, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"   Data dictionary saved\")\n",
    "    \n",
    "    return data_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9039d4b5-5661-4530-8841-e836ce65be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_quality_report(master_data):\n",
    "    \"\"\"Generate comprehensive data quality report\"\"\"\n",
    "    print(\"Generating Data Quality Report...\")\n",
    "    \n",
    "    report = {\n",
    "        'overview': {\n",
    "            'total_records': len(master_data),\n",
    "            'unique_players': master_data['Player_Clean'].nunique(),\n",
    "            'seasons': sorted(master_data['Season'].unique()),\n",
    "            'teams': len(master_data['Team_Clean'].dropna().unique()),\n",
    "            'positions': sorted(master_data['Pos'].dropna().unique()) if 'Pos' in master_data.columns else []\n",
    "        },\n",
    "        'completeness': {},\n",
    "        'data_quality_flags': [],\n",
    "        'summary_stats': {}\n",
    "    }\n",
    "\n",
    "    key_columns = ['Player_Clean', 'Season', 'Team_Clean', 'PTS', 'TRB', 'AST', 'Age', 'G', 'MP']\n",
    "    if 'PER' in master_data.columns:\n",
    "        key_columns.extend(['PER', 'VORP', 'BPM', 'WS'])\n",
    "    if 'Current_Salary' in master_data.columns:\n",
    "        key_columns.append('Current_Salary')\n",
    "    \n",
    "    for col in key_columns:\n",
    "        if col in master_data.columns:\n",
    "            completeness = (master_data[col].notna().mean() * 100)\n",
    "            report['completeness'][col] = f\"{completeness:.1f}%\"\n",
    "\n",
    "    numeric_cols = ['Age', 'G', 'MP', 'PTS', 'TRB', 'AST']\n",
    "    if 'Current_Salary' in master_data.columns:\n",
    "        numeric_cols.append('Current_Salary')\n",
    "    if 'Points_Per_Million' in master_data.columns:\n",
    "        numeric_cols.extend(['Points_Per_Million', 'WinShares_Per_Million', 'VORP_Per_Million'])\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in master_data.columns:\n",
    "            col_data = master_data[col].dropna()\n",
    "            if len(col_data) > 0:\n",
    "                if col == 'Current_Salary':\n",
    "                    # Convert to millions for readability\n",
    "                    col_data = col_data / 1000000\n",
    "                    unit = 'M'\n",
    "                else:\n",
    "                    unit = ''\n",
    "                \n",
    "                report['summary_stats'][col] = {\n",
    "                    'mean': f\"{col_data.mean():.1f}{unit}\",\n",
    "                    'median': f\"{col_data.median():.1f}{unit}\",\n",
    "                    'min': f\"{col_data.min():.1f}{unit}\",\n",
    "                    'max': f\"{col_data.max():.1f}{unit}\",\n",
    "                    'std': f\"{col_data.std():.1f}{unit}\"\n",
    "                }\n",
    "\n",
    "    if 'Age' in master_data.columns:\n",
    "        young_players = (master_data['Age'] < 20).sum()\n",
    "        old_players = (master_data['Age'] > 40).sum()\n",
    "        if young_players > 0:\n",
    "            report['data_quality_flags'].append(f\"{young_players} very young players (age < 20)\")\n",
    "        if old_players > 0:\n",
    "            report['data_quality_flags'].append(f\"{old_players} very old players (age > 40)\")\n",
    "\n",
    "    season_counts = master_data['Season'].value_counts().sort_index()\n",
    "    report['season_distribution'] = season_counts.to_dict()\n",
    "\n",
    "    if 'Current_Salary' in master_data.columns:\n",
    "        salary_data = master_data[master_data['Current_Salary'].notna()]\n",
    "        if len(salary_data) > 0:\n",
    "            report['salary_analysis'] = {\n",
    "                'players_with_salary': len(salary_data),\n",
    "                'salary_tiers': master_data['Salary_Tier'].value_counts().to_dict() if 'Salary_Tier' in master_data.columns else {},\n",
    "                'efficiency_metrics_coverage': {\n",
    "                    'Points_Per_Million': master_data['Points_Per_Million'].notna().sum() if 'Points_Per_Million' in master_data.columns else 0,\n",
    "                    'WinShares_Per_Million': master_data['WinShares_Per_Million'].notna().sum() if 'WinShares_Per_Million' in master_data.columns else 0,\n",
    "                    'VORP_Per_Million': master_data['VORP_Per_Million'].notna().sum() if 'VORP_Per_Million' in master_data.columns else 0\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    with open('data/processed/data_quality_report.json', 'w') as f:\n",
    "        json.dump(report, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"   Data quality report saved\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nDATA QUALITY SUMMARY:\")\n",
    "    print(f\"   Dataset completeness: Good\")\n",
    "    print(f\"   Key metrics coverage: {len([col for col in key_columns if col in master_data.columns])}/{len(key_columns)} columns\")\n",
    "    print(f\"   Data quality flags: {len(report['data_quality_flags'])} issues detected\")\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "212f9a66-bcad-42c3-a802-11010f4a4919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_analyses(master_data):\n",
    "    \"\"\"Create sample analyses to validate the data\"\"\"\n",
    "    print(\"Creating sample validation analyses...\")\n",
    "    \n",
    "    analyses = {}\n",
    "\n",
    "    if 'PTS' in master_data.columns:\n",
    "        print(\"   Top scorers by season\")\n",
    "        top_scorers = []\n",
    "        for season in sorted(master_data['Season'].unique()):\n",
    "            season_data = master_data[\n",
    "                (master_data['Season'] == season) & \n",
    "                (master_data.get('Significant_Player', True))\n",
    "            ]\n",
    "            if len(season_data) > 0 and season_data['PTS'].notna().any():\n",
    "                top_scorer = season_data.loc[season_data['PTS'].idxmax()]\n",
    "                top_scorers.append({\n",
    "                    'season': season,\n",
    "                    'player': top_scorer['Player_Clean'],\n",
    "                    'points': top_scorer['PTS'],\n",
    "                    'team': top_scorer['Team_Clean']\n",
    "                })\n",
    "        analyses['top_scorers'] = top_scorers\n",
    "\n",
    "    if 'Points_Per_Million' in master_data.columns:\n",
    "        print(\"   Salary efficiency leaders\")\n",
    "        current_season = master_data[\n",
    "            (master_data['Season'] == 2025) & \n",
    "            (master_data['Points_Per_Million'].notna()) &\n",
    "            (master_data['Current_Salary'].notna())\n",
    "        ]\n",
    "        if len(current_season) > 0:\n",
    "            # Filter for significant players only\n",
    "            if 'Significant_Player' in current_season.columns:\n",
    "                current_season = current_season[current_season['Significant_Player'] == True]\n",
    "            \n",
    "            efficiency_leaders = current_season.nlargest(10, 'Points_Per_Million')[\n",
    "                ['Player_Clean', 'Team_Clean', 'Points_Per_Million', 'Salary_Millions', 'PTS', 'TRB', 'AST']\n",
    "            ].to_dict('records')\n",
    "            analyses['efficiency_leaders'] = efficiency_leaders\n",
    "\n",
    "    if 'Current_Salary' in master_data.columns:\n",
    "        print(\"   Team salary analysis\")\n",
    "        team_salaries = master_data[\n",
    "            (master_data['Season'] == 2025) & \n",
    "            (master_data['Current_Salary'].notna())\n",
    "        ].groupby('Team_Clean')['Current_Salary'].agg(['sum', 'mean', 'count']).round(0)\n",
    "        \n",
    "        # Convert to millions\n",
    "        team_salaries['sum'] = team_salaries['sum'] / 1000000\n",
    "        team_salaries['mean'] = team_salaries['mean'] / 1000000\n",
    "        \n",
    "        analyses['team_salary_summary'] = team_salaries.to_dict('index')\n",
    "\n",
    "    if 'Career_Stage' in master_data.columns:\n",
    "        career_distribution = master_data['Career_Stage'].value_counts().to_dict()\n",
    "        analyses['career_stage_distribution'] = career_distribution\n",
    "\n",
    "    advanced_metrics = ['PER', 'VORP', 'BPM', 'WS']\n",
    "    for metric in advanced_metrics:\n",
    "        if metric in master_data.columns:\n",
    "            # Get top 5 for 2025 season\n",
    "            metric_leaders = master_data[\n",
    "                (master_data['Season'] == 2025) & \n",
    "                (master_data[metric].notna())\n",
    "            ]\n",
    "            if len(metric_leaders) > 0:\n",
    "                if 'Significant_Player' in metric_leaders.columns:\n",
    "                    metric_leaders = metric_leaders[metric_leaders['Significant_Player'] == True]\n",
    "                \n",
    "                top_5 = metric_leaders.nlargest(5, metric)[\n",
    "                    ['Player_Clean', 'Team_Clean', metric]\n",
    "                ].to_dict('records')\n",
    "                analyses[f'top_{metric.lower()}_2025'] = top_5\n",
    "\n",
    "    with open('data/processed/sample_analyses.json', 'w') as f:\n",
    "        json.dump(analyses, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"   Sample analyses saved\")\n",
    "\n",
    "    if 'top_scorers' in analyses and len(analyses['top_scorers']) > 0:\n",
    "        print(f\"\\nSample Insight - Top Scorers:\")\n",
    "        for scorer in analyses['top_scorers'][-3:]:  # Last 3 seasons\n",
    "            print(f\"   {scorer['season']}: {scorer['player']} ({scorer['points']:.0f} pts)\")\n",
    "    \n",
    "    if 'efficiency_leaders' in analyses and len(analyses['efficiency_leaders']) > 0:\n",
    "        print(f\"\\nSample Insight - Most Efficient Players (2025):\")\n",
    "        for i, player in enumerate(analyses['efficiency_leaders'][:3]):\n",
    "            print(f\"   {i+1}. {player['Player_Clean']}: {player['Points_Per_Million']:.1f} points/million\")\n",
    "    \n",
    "    if 'career_stage_distribution' in analyses:\n",
    "        print(f\"\\nCareer Stage Distribution:\")\n",
    "        for stage, count in analyses['career_stage_distribution'].items():\n",
    "            print(f\"   {stage}: {count} players\")\n",
    "    \n",
    "    return analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f207a11-dc04-478a-9666-f570f90dbeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_summary(master_data, data_dict, quality_report, sample_analyses):\n",
    "    \"\"\"Generate final summary of Day 3 results\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DAY 3 COMPLETE - DATA CLEANING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nDATASET OVERVIEW:\")\n",
    "    print(f\"   Total player-seasons: {len(master_data):,}\")\n",
    "    print(f\"   Unique players: {master_data['Player_Clean'].nunique():,}\")\n",
    "    print(f\"   Seasons covered: {sorted(master_data['Season'].unique())}\")\n",
    "    print(f\"   Teams represented: {len(master_data['Team_Clean'].dropna().unique())}\")\n",
    "    \n",
    "    print(f\"\\nSALARY DATA COVERAGE:\")\n",
    "    salary_coverage = master_data['Current_Salary'].notna()\n",
    "    print(f\"   Players with salary data: {salary_coverage.sum():,} ({salary_coverage.mean()*100:.1f}%)\")\n",
    "    \n",
    "    if salary_coverage.any():\n",
    "        salary_data = master_data[salary_coverage]['Current_Salary']\n",
    "        print(f\"   Salary range: ${salary_data.min()/1000000:.1f}M - ${salary_data.max()/1000000:.1f}M\")\n",
    "        print(f\"   Average salary: ${salary_data.mean()/1000000:.1f}M\")\n",
    "    \n",
    "    print(f\"\\nEFFICIENCY METRICS CREATED:\")\n",
    "    efficiency_cols = [col for col in master_data.columns if 'Per_Million' in col]\n",
    "    for col in efficiency_cols:\n",
    "        coverage = master_data[col].notna().sum()\n",
    "        print(f\"   {col}: {coverage:,} players\")\n",
    "    \n",
    "    print(f\"\\nDATA QUALITY:\")\n",
    "    key_metrics = ['PTS', 'TRB', 'AST', 'PER', 'VORP', 'BPM', 'WS']\n",
    "    for metric in key_metrics:\n",
    "        if metric in master_data.columns:\n",
    "            coverage = master_data[metric].notna().mean() * 100\n",
    "            print(f\"   {metric}: {coverage:.1f}% coverage\")\n",
    "    \n",
    "    print(f\"\\nFILES CREATED:\")\n",
    "    print(f\"   data/processed/master_nba_data.csv\")\n",
    "    print(f\"   data/processed/data_dictionary.json\")  \n",
    "    print(f\"   data/processed/data_quality_report.json\")\n",
    "    print(f\"   data/processed/sample_analyses.json\")\n",
    "    print(f\"   data/processed/individual/ (3 individual clean datasets)\")\n",
    "    \n",
    "    print(f\"   Load master_nba_data.csv for analysis\")\n",
    "    print(f\"   Focus: Exploratory Data Analysis\")\n",
    "    print(f\"   Focus: Feature Engineering\")\n",
    "    print(f\"   Focus: Contract efficiency analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d358a631-828b-4b3a-81c4-dc4ff9b73ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cleaned datasets...\n",
      "   Master dataset saved: 3,360 records\n",
      "   Individual datasets saved\n",
      "   Data dictionary saved\n",
      "Generating Data Quality Report...\n",
      "   Data quality report saved\n",
      "\n",
      "DATA QUALITY SUMMARY:\n",
      "   Dataset completeness: Good\n",
      "   Key metrics coverage: 14/14 columns\n",
      "   Data quality flags: 2 issues detected\n",
      "Creating sample validation analyses...\n",
      "   Top scorers by season\n",
      "   Salary efficiency leaders\n",
      "   Team salary analysis\n",
      "   Sample analyses saved\n",
      "\n",
      "Sample Insight - Top Scorers:\n",
      "   2023: Jayson Tatum (2225 pts)\n",
      "   2024: Luka Dončić (2370 pts)\n",
      "   2025: Shai Gilgeous-Alexander (2484 pts)\n",
      "\n",
      "Sample Insight - Most Efficient Players (2025):\n",
      "   1. Jaylen Wells: 420.9 points/million\n",
      "   2. Toumani Camara: 397.0 points/million\n",
      "   3. Scotty Pippen Jr.: 343.1 points/million\n",
      "\n",
      "Career Stage Distribution:\n",
      "   Developing: 1210 players\n",
      "   Rookie/Young: 1167 players\n",
      "   Prime: 492 players\n",
      "   Veteran: 362 players\n",
      "   Late Career: 123 players\n",
      "   Unknown: 6 players\n",
      "\n",
      "============================================================\n",
      "DAY 3 COMPLETE - DATA CLEANING SUMMARY\n",
      "============================================================\n",
      "\n",
      "DATASET OVERVIEW:\n",
      "   Total player-seasons: 3,360\n",
      "   Unique players: 1,069\n",
      "   Seasons covered: [2020, 2021, 2022, 2023, 2024, 2025]\n",
      "   Teams represented: 33\n",
      "\n",
      "SALARY DATA COVERAGE:\n",
      "   Players with salary data: 219 (6.5%)\n",
      "   Salary range: $0.7M - $59.6M\n",
      "   Average salary: $16.4M\n",
      "\n",
      "EFFICIENCY METRICS CREATED:\n",
      "   Points_Per_Million: 219 players\n",
      "   WinShares_Per_Million: 219 players\n",
      "   VORP_Per_Million: 219 players\n",
      "\n",
      "DATA QUALITY:\n",
      "   PTS: 100.0% coverage\n",
      "   TRB: 100.0% coverage\n",
      "   AST: 100.0% coverage\n",
      "   PER: 100.0% coverage\n",
      "   VORP: 100.0% coverage\n",
      "   BPM: 100.0% coverage\n",
      "   WS: 100.0% coverage\n",
      "\n",
      "FILES CREATED:\n",
      "   data/processed/master_nba_data.csv\n",
      "   data/processed/data_dictionary.json\n",
      "   data/processed/data_quality_report.json\n",
      "   data/processed/sample_analyses.json\n",
      "   data/processed/individual/ (3 individual clean datasets)\n",
      "   Load master_nba_data.csv for analysis\n",
      "   Focus: Exploratory Data Analysis\n",
      "   Focus: Feature Engineering\n",
      "   Focus: Contract efficiency analysis\n"
     ]
    }
   ],
   "source": [
    "if 'master_nba_data' in locals():\n",
    "    data_dict = save_clean_datasets(\n",
    "        master_nba_data, \n",
    "        clean_player_stats_df, \n",
    "        clean_advanced_stats_df, \n",
    "        clean_salary_data_df\n",
    "    )\n",
    "\n",
    "    quality_report = create_data_quality_report(master_nba_data)\n",
    "\n",
    "    sample_analyses = create_sample_analyses(master_nba_data)\n",
    "\n",
    "    generate_final_summary(master_nba_data, data_dict, quality_report, sample_analyses)\n",
    "    \n",
    "else:\n",
    "    print(\"Error: Master dataset not available. Please run previous phases first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bdc19e-8d6e-493e-87a8-e96d65a3b1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
